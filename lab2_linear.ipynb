{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2: Логистическая и линейная регрессия\n",
    "\n",
    "1. Бейзлайн sklearn\n",
    "2. Улучшение через подбор гиперпараметров\n",
    "3. Собственная имплементация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек\n",
    "Импортируем необходимые библиотеки для работы с данными, моделями машинного обучения и метриками качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:23.552397Z",
     "iopub.status.busy": "2025-12-14T18:51:23.552233Z",
     "iopub.status.idle": "2025-12-14T18:51:24.346952Z",
     "shell.execute_reply": "2025-12-14T18:51:24.346643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Импорт завершён\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.metrics import f1_score, roc_auc_score, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import openml\n",
    "import kagglehub\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Импорт завершён\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет классификации: APS Failure at Scania Trucks\n",
    "Загружаем данные из OpenML (ID 41138). Заполняем пропуски медианой и сэмплируем 15000 объектов для ускорения экспериментов. Разделяем на train/test с сохранением стратификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:24.361115Z",
     "iopub.status.busy": "2025-12-14T18:51:24.360963Z",
     "iopub.status.idle": "2025-12-14T18:51:25.197692Z",
     "shell.execute_reply": "2025-12-14T18:51:25.197325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классификация: (12000, 170)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка классификации\n",
    "dataset = openml.datasets.get_dataset(41138)\n",
    "X_clf, y_clf, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
    "y_clf_enc = (y_clf == 'pos').astype(int)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_clf_imp = pd.DataFrame(imputer.fit_transform(X_clf), columns=X_clf.columns)\n",
    "np.random.seed(42)\n",
    "idx = np.random.choice(len(X_clf_imp), 15000, replace=False)\n",
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(\n",
    "    X_clf_imp.iloc[idx], y_clf_enc.iloc[idx], test_size=0.2, random_state=42, stratify=y_clf_enc.iloc[idx]\n",
    ")\n",
    "print(f\"Классификация: {X_clf_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет регрессии: Avocado Prices\n",
    "Загружаем данные о ценах авокадо с Kaggle. Кодируем категориальные признаки (тип, регион) и выбираем числовые признаки для предсказания средней цены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:25.198884Z",
     "iopub.status.busy": "2025-12-14T18:51:25.198813Z",
     "iopub.status.idle": "2025-12-14T18:51:26.055910Z",
     "shell.execute_reply": "2025-12-14T18:51:26.055312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Регрессия: (14599, 8)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка регрессии: Avocado Prices\n",
    "path = kagglehub.dataset_download(\"neuromusic/avocado-prices\")\n",
    "df = pd.read_csv(os.path.join(path, \"avocado.csv\"))\n",
    "df['type_enc'] = LabelEncoder().fit_transform(df['type'])\n",
    "df['region_enc'] = LabelEncoder().fit_transform(df['region'])\n",
    "features = ['Total Volume', '4046', '4225', '4770', 'Total Bags', 'year', 'type_enc', 'region_enc']\n",
    "X_reg = df[features].values\n",
    "y_reg = df['AveragePrice'].values\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "print(f\"Регрессия: {X_reg_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Бейзлайн"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабируем признаки с помощью StandardScaler и обучаем базовую логистическую регрессию. Масштабирование важно для корректной работы регуляризации и ускорения сходимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:26.057243Z",
     "iopub.status.busy": "2025-12-14T18:51:26.057148Z",
     "iopub.status.idle": "2025-12-14T18:51:26.153141Z",
     "shell.execute_reply": "2025-12-14T18:51:26.152677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== БЕЙЗЛАЙН: Logistic Regression ===\n",
      "F1: 0.6833, ROC-AUC: 0.9356\n"
     ]
    }
   ],
   "source": [
    "# Масштабирование\n",
    "scaler_clf = StandardScaler()\n",
    "X_clf_train_sc = scaler_clf.fit_transform(X_clf_train)\n",
    "X_clf_test_sc = scaler_clf.transform(X_clf_test)\n",
    "scaler_reg = StandardScaler()\n",
    "X_reg_train_sc = scaler_reg.fit_transform(X_reg_train)\n",
    "X_reg_test_sc = scaler_reg.transform(X_reg_test)\n",
    "\n",
    "# Бейзлайн классификация\n",
    "log_reg_base = LogisticRegression(max_iter=1000)\n",
    "log_reg_base.fit(X_clf_train_sc, y_clf_train)\n",
    "y_pred_base = log_reg_base.predict(X_clf_test_sc)\n",
    "y_proba_base = log_reg_base.predict_proba(X_clf_test_sc)[:, 1]\n",
    "f1_base = f1_score(y_clf_test, y_pred_base)\n",
    "roc_base = roc_auc_score(y_clf_test, y_proba_base)\n",
    "print(f\"=== БЕЙЗЛАЙН: Logistic Regression ===\")\n",
    "print(f\"F1: {f1_base:.4f}, ROC-AUC: {roc_base:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем базовую модель LinearRegression из sklearn. Оцениваем качество по RMSE и R². Линейная регрессия не требует подбора гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:26.154225Z",
     "iopub.status.busy": "2025-12-14T18:51:26.154161Z",
     "iopub.status.idle": "2025-12-14T18:51:26.157701Z",
     "shell.execute_reply": "2025-12-14T18:51:26.157321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== БЕЙЗЛАЙН: Linear Regression ===\n",
      "RMSE: 0.3133, R²: 0.3892\n"
     ]
    }
   ],
   "source": [
    "# Бейзлайн регрессия\n",
    "lin_reg_base = LinearRegression()\n",
    "lin_reg_base.fit(X_reg_train_sc, y_reg_train)\n",
    "y_pred_reg_base = lin_reg_base.predict(X_reg_test_sc)\n",
    "rmse_base = np.sqrt(mean_squared_error(y_reg_test, y_pred_reg_base))\n",
    "r2_base = r2_score(y_reg_test, y_pred_reg_base)\n",
    "print(f\"=== БЕЙЗЛАЙН: Linear Regression ===\")\n",
    "print(f\"RMSE: {rmse_base:.4f}, R²: {r2_base:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров логистической регрессии: коэффициент регуляризации `C` и балансировка классов `class_weight`. Оптимизируем по F1-score с помощью кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:26.158718Z",
     "iopub.status.busy": "2025-12-14T18:51:26.158665Z",
     "iopub.status.idle": "2025-12-14T18:51:28.475802Z",
     "shell.execute_reply": "2025-12-14T18:51:28.475307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'C': 1.0, 'class_weight': None}\n",
      "=== УЛУЧШЕННЫЙ ===\n",
      "F1: 0.6833 (+0.0000)\n",
      "ROC-AUC: 0.9356\n"
     ]
    }
   ],
   "source": [
    "# GridSearch для классификации\n",
    "param_grid = {'C': [0.1, 1.0, 10.0], 'class_weight': [None, 'balanced']}\n",
    "grid_clf = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_clf.fit(X_clf_train_sc, y_clf_train)\n",
    "\n",
    "print(f\"Лучшие параметры: {grid_clf.best_params_}\")\n",
    "y_pred_imp = grid_clf.predict(X_clf_test_sc)\n",
    "y_proba_imp = grid_clf.predict_proba(X_clf_test_sc)[:, 1]\n",
    "f1_imp = f1_score(y_clf_test, y_pred_imp)\n",
    "roc_imp = roc_auc_score(y_clf_test, y_proba_imp)\n",
    "print(f\"=== УЛУЧШЕННЫЙ ===\")\n",
    "print(f\"F1: {f1_imp:.4f} ({f1_imp-f1_base:+.4f})\")\n",
    "print(f\"ROC-AUC: {roc_imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем Ridge-регрессию (L2-регуляризация) для борьбы с переобучением. Подбираем коэффициент регуляризации `alpha` через GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:28.476916Z",
     "iopub.status.busy": "2025-12-14T18:51:28.476842Z",
     "iopub.status.idle": "2025-12-14T18:51:28.502866Z",
     "shell.execute_reply": "2025-12-14T18:51:28.502568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший alpha: 10.0\n",
      "=== УЛУЧШЕННЫЙ: Ridge ===\n",
      "RMSE: 0.3133 (+0.0000)\n",
      "R²: 0.3890 (-0.0002)\n"
     ]
    }
   ],
   "source": [
    "# Ridge регрессия\n",
    "grid_reg = GridSearchCV(Ridge(), {'alpha': [0.1, 1.0, 10.0, 100.0]}, cv=3, scoring='r2', n_jobs=-1)\n",
    "grid_reg.fit(X_reg_train_sc, y_reg_train)\n",
    "print(f\"Лучший alpha: {grid_reg.best_params_['alpha']}\")\n",
    "y_pred_reg_imp = grid_reg.predict(X_reg_test_sc)\n",
    "rmse_imp = np.sqrt(mean_squared_error(y_reg_test, y_pred_reg_imp))\n",
    "r2_imp = r2_score(y_reg_test, y_pred_reg_imp)\n",
    "print(f\"=== УЛУЧШЕННЫЙ: Ridge ===\")\n",
    "print(f\"RMSE: {rmse_imp:.4f} ({rmse_imp-rmse_base:+.4f})\")\n",
    "print(f\"R²: {r2_imp:.4f} ({r2_imp-r2_base:+.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Собственная имплементация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем алгоритмы с нуля:\n",
    "- **MyLinearRegression**: Аналитическое решение через псевдообратную матрицу (формула нормального уравнения)\n",
    "- **MyLogisticRegression**: Градиентный спуск с L2-регуляризацией. Используем сигмоиду для преобразования в вероятности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:28.504067Z",
     "iopub.status.busy": "2025-12-14T18:51:28.503997Z",
     "iopub.status.idle": "2025-12-14T18:51:28.506890Z",
     "shell.execute_reply": "2025-12-14T18:51:28.506612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реализации готовы!\n"
     ]
    }
   ],
   "source": [
    "class MyLinearRegression:\n",
    "    \"\"\"Линейная регрессия (аналитическое решение)\"\"\"\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        X_b = np.c_[np.ones(len(X)), X]\n",
    "        theta = np.linalg.pinv(X_b.T @ X_b) @ X_b.T @ y\n",
    "        self.b, self.w = theta[0], theta[1:]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array(X) @ self.w + self.b\n",
    "\n",
    "class MyLogisticRegression:\n",
    "    \"\"\"Логистическая регрессия (градиентный спуск)\"\"\"\n",
    "    def __init__(self, lr=0.1, n_iter=1000, C=1.0):\n",
    "        self.lr, self.n_iter, self.C = lr, n_iter, C\n",
    "        self.w = self.b = None\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        n, m = X.shape\n",
    "        self.w, self.b = np.zeros(m), 0\n",
    "        for _ in range(self.n_iter):\n",
    "            p = self._sigmoid(X @ self.w + self.b)\n",
    "            error = p - y\n",
    "            self.w -= self.lr * ((X.T @ error) / n + self.w / self.C)\n",
    "            self.b -= self.lr * np.mean(error)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        p = self._sigmoid(np.array(X) @ self.w + self.b)\n",
    "        return np.c_[1-p, p]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X)[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "print(\"Реализации готовы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестируем собственную реализацию логистической регрессии. Обучаем на масштабированных данных и сравниваем результаты со sklearn-бейзлайном по метрикам F1 и ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:28.507772Z",
     "iopub.status.busy": "2025-12-14T18:51:28.507706Z",
     "iopub.status.idle": "2025-12-14T18:51:29.129695Z",
     "shell.execute_reply": "2025-12-14T18:51:29.129211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== СВОЯ: Логистическая регрессия ===\n",
      "Оптимальный порог: 0.05\n",
      "F1: 0.5814 (sklearn: 0.6833)\n",
      "ROC-AUC: 0.9726\n"
     ]
    }
   ],
   "source": [
    "# Своя классификация\n",
    "my_log = MyLogisticRegression(lr=0.1, n_iter=2000, C=1.0)\n",
    "my_log.fit(X_clf_train_sc, y_clf_train.values)\n",
    "my_proba = my_log.predict_proba(X_clf_test_sc)[:, 1]\n",
    "\n",
    "# Подбор оптимального порога по F1 (для несбалансированных данных порог 0.5 не оптимален)\n",
    "best_thresh, best_f1 = 0.5, 0\n",
    "for thresh in np.arange(0.05, 0.95, 0.05):\n",
    "    pred = (my_proba >= thresh).astype(int)\n",
    "    f1 = f1_score(y_clf_test, pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_thresh = f1, thresh\n",
    "\n",
    "my_pred = (my_proba >= best_thresh).astype(int)\n",
    "my_f1 = f1_score(y_clf_test, my_pred)\n",
    "my_roc = roc_auc_score(y_clf_test, my_proba)\n",
    "print(f\"=== СВОЯ: Логистическая регрессия ===\")\n",
    "print(f\"Оптимальный порог: {best_thresh:.2f}\")\n",
    "print(f\"F1: {my_f1:.4f} (sklearn: {f1_base:.4f})\")\n",
    "print(f\"ROC-AUC: {my_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестируем собственную реализацию линейной регрессии на задаче предсказания цены авокадо. Используем аналитическое решение (метод наименьших квадратов). Результаты должны совпадать со sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:29.130736Z",
     "iopub.status.busy": "2025-12-14T18:51:29.130673Z",
     "iopub.status.idle": "2025-12-14T18:51:29.133478Z",
     "shell.execute_reply": "2025-12-14T18:51:29.133081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== СВОЯ: Линейная регрессия ===\n",
      "RMSE: 0.3133 (sklearn: 0.3133)\n",
      "R²: 0.3892 (sklearn: 0.3892)\n"
     ]
    }
   ],
   "source": [
    "# Своя регрессия\n",
    "my_lin = MyLinearRegression()\n",
    "my_lin.fit(X_reg_train_sc, y_reg_train)\n",
    "my_pred_reg = my_lin.predict(X_reg_test_sc)\n",
    "my_rmse = np.sqrt(mean_squared_error(y_reg_test, my_pred_reg))\n",
    "my_r2 = r2_score(y_reg_test, my_pred_reg)\n",
    "print(f\"=== СВОЯ: Линейная регрессия ===\")\n",
    "print(f\"RMSE: {my_rmse:.4f} (sklearn: {rmse_base:.4f})\")\n",
    "print(f\"R²: {my_r2:.4f} (sklearn: {r2_base:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговая сводка\n",
    "\n",
    "Сравниваем все модели: бейзлайн sklearn, улучшенный вариант и собственную реализацию. Для классификации — F1 и ROC-AUC, для регрессии — RMSE и R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T18:51:29.134498Z",
     "iopub.status.busy": "2025-12-14T18:51:29.134438Z",
     "iopub.status.idle": "2025-12-14T18:51:29.136764Z",
     "shell.execute_reply": "2025-12-14T18:51:29.136503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ИТОГОВАЯ СВОДКА: ЛАБОРАТОРНАЯ РАБОТА №2 (Линейные модели)\n",
      "======================================================================\n",
      "\n",
      "----------------------------КЛАССИФИКАЦИЯ-----------------------------\n",
      "Модель                         F1           ROC-AUC     \n",
      "------------------------------------------------------\n",
      "Бейзлайн sklearn               0.6833       0.9356      \n",
      "Улучшенный sklearn             0.6833       0.9356      \n",
      "Своя реализация                0.5814       0.9726      \n",
      "\n",
      "----------------------РЕГРЕССИЯ (Avocado Prices)----------------------\n",
      "Модель                         RMSE         R²          \n",
      "------------------------------------------------------\n",
      "Бейзлайн sklearn               0.3133       0.3892      \n",
      "Улучшенный sklearn             0.3133       0.3890      \n",
      "Своя реализация                0.3133       0.3892      \n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ИТОГОВАЯ СВОДКА: ЛАБОРАТОРНАЯ РАБОТА №2 (Линейные модели)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'КЛАССИФИКАЦИЯ':-^70}\")\n",
    "print(f\"{'Модель':<30} {'F1':<12} {'ROC-AUC':<12}\")\n",
    "print(\"-\"*54)\n",
    "print(f\"{'Бейзлайн sklearn':<30} {f1_base:<12.4f} {roc_base:<12.4f}\")\n",
    "print(f\"{'Улучшенный sklearn':<30} {f1_imp:<12.4f} {roc_imp:<12.4f}\")\n",
    "print(f\"{'Своя реализация':<30} {my_f1:<12.4f} {my_roc:<12.4f}\")\n",
    "print(f\"\\n{'РЕГРЕССИЯ (Avocado Prices)':-^70}\")\n",
    "print(f\"{'Модель':<30} {'RMSE':<12} {'R²':<12}\")\n",
    "print(\"-\"*54)\n",
    "print(f\"{'Бейзлайн sklearn':<30} {rmse_base:<12.4f} {r2_base:<12.4f}\")\n",
    "print(f\"{'Улучшенный sklearn':<30} {rmse_imp:<12.4f} {r2_imp:<12.4f}\")\n",
    "print(f\"{'Своя реализация':<30} {my_rmse:<12.4f} {my_r2:<12.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
